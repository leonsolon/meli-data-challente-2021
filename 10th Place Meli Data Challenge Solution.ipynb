{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leon Silva - 10th Place Solution - Meli Data Challenge 2021\n",
    "\n",
    "First of all I'd like to thank Mercado Libre for this great contest. I'd also like to thank MÃ¡rio Filho for sharing so much of his approach which gave me a huge head start: most of my solution got the ideas (and implementation) from him. With a litte feature engineering + ensemble with non-ML predictions + post processing I was able to get to the 10th place.\n",
    "\n",
    "#### Business Understanding\n",
    "\n",
    "Given the sales of 600k+ products between february and march of 2021, we were asked to predict the inventory days of these products in april of 2021. The items were sold in three countries: Argentina, Brazil and Mexico. \n",
    "\n",
    "Moreover, the predictions should be presented in terms of the probability of selling out in the 30 days of April. It's given that all products are sold within 30 days.\n",
    "\n",
    "The task as stated in the Challenge:\n",
    "\n",
    "\"Your task is to predict how long it will take for the inventory of a certain item to be sold completely. In inventory management theory this concept is known as inventory days.\n",
    "\n",
    "In the evaluation set you will be given the item target stock, and you will have to provide a prediction for the number of days it will take to run out. Possible values range from 1 to 30. Rather than giving a point estimate, you are expected to provide a score for each the possible outcomes.\n",
    "\n",
    "To put it simply, you need to answer the following question:\n",
    "\n",
    "'What are the odds that the target stock will be sold out in one day?', 'What about in two days?' and so on until day 30.\"\n",
    "\n",
    "#### Data Understanding\n",
    "\n",
    "We were given three files:\n",
    "* The first file has the information about the sales in Februrary and March of 2021 of 600k+ products, with features regarding the products in each day: price, minutes active in the last 24 hours and number os itens sold that day\n",
    "* The second had the metadata of the products\n",
    "* Finally, the test file has the skus (unique id for each product) with the inventory to predict the inventory days\n",
    "\n",
    "#### Modeling\n",
    "\n",
    "I used a simple regressor to find how many items were sold in the last day of prediction. With this information, we can calculate the inventory days: items_sold_prediction / inventory_in_test\n",
    "\n",
    "The validation were the mean RDS between the traning in february and validating in march and vice-versa.\n",
    "\n",
    "Besides the creation of features that helped improving the solution, the different approaches I did different from other solutions were:\n",
    "* I've created an ensemble model with XGBRegressor and a naive predictor (average sales)\n",
    "* I've done post processing setting 30 inventory days to the skus which stock were too big considering the sales on the previous months\n",
    "\n",
    "I tryed different distributions, but in the end, tweedie was the best one to calculate the submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries \n",
    "# numpy and pandas, because... ah, you know what for :)\n",
    "# gp_minimize to tune the XGB hyperparameteres\n",
    "# utils has functions to calculate the tweedie distribution and to read the json file into a list (thanks Mario Filho and Meli)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skopt import gp_minimize\n",
    "from xgboost import XGBRegressor\n",
    "import tweedie\n",
    "import os\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [......................................] 135913048 / 135913048"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "\n",
    "# Create data folder if it does not exist\n",
    "if not os.path.isdir('./data'):\n",
    "    os.mkdir('./data')\n",
    "\n",
    "# Download the files from Meli Data Challenge website    \n",
    "train_data_url = 'https://meli-data-challenge.s3.amazonaws.com/2021/train_data.parquet'\n",
    "test_data_url = 'https://meli-data-challenge.s3.amazonaws.com/2021/test_data.csv'\n",
    "details_url = 'https://meli-data-challenge.s3.amazonaws.com/2021/items_static_metadata_full.jl'\n",
    "\n",
    "urls = [train_data_url, test_data_url, details_url]\n",
    "\n",
    "for url in urls:\n",
    "    file_name = os.path.split(url)[1]\n",
    "    if not os.path.isfile(f'./data/{file_name}'):\n",
    "        wget.download(url, f'./data/{file_name}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train data\n",
    "train = pd.read_parquet('./data/train_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>date</th>\n",
       "      <th>sold_quantity</th>\n",
       "      <th>current_price</th>\n",
       "      <th>currency</th>\n",
       "      <th>listing_type</th>\n",
       "      <th>shipping_logistic_type</th>\n",
       "      <th>shipping_payment</th>\n",
       "      <th>minutes_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>464801</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>156.78</td>\n",
       "      <td>REA</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>464801</td>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>156.78</td>\n",
       "      <td>REA</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>464801</td>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>0</td>\n",
       "      <td>156.78</td>\n",
       "      <td>REA</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>464801</td>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>0</td>\n",
       "      <td>156.78</td>\n",
       "      <td>REA</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>464801</td>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>156.78</td>\n",
       "      <td>REA</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sku        date  sold_quantity  current_price currency listing_type  \\\n",
       "0  464801  2021-02-01              0         156.78      REA      classic   \n",
       "1  464801  2021-02-02              0         156.78      REA      classic   \n",
       "2  464801  2021-02-03              0         156.78      REA      classic   \n",
       "3  464801  2021-02-04              0         156.78      REA      classic   \n",
       "4  464801  2021-02-05              1         156.78      REA      classic   \n",
       "\n",
       "  shipping_logistic_type shipping_payment  minutes_active  \n",
       "0            fulfillment    free_shipping          1440.0  \n",
       "1            fulfillment    free_shipping          1440.0  \n",
       "2            fulfillment    free_shipping          1440.0  \n",
       "3            fulfillment    free_shipping          1440.0  \n",
       "4            fulfillment    free_shipping          1440.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 660916 skus'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of products\n",
    "f'There are {len(train[\"sku\"].unique())} skus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the metadata\n",
    "list_details = utils.json_to_list('./data/items_static_metadata_full.jl')\n",
    "df_details = pd.DataFrame(data=list_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>date</th>\n",
       "      <th>sold_quantity</th>\n",
       "      <th>current_price</th>\n",
       "      <th>currency</th>\n",
       "      <th>listing_type</th>\n",
       "      <th>shipping_logistic_type</th>\n",
       "      <th>shipping_payment</th>\n",
       "      <th>minutes_active</th>\n",
       "      <th>item_domain_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_title</th>\n",
       "      <th>site_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_family_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>464801</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>156.78</td>\n",
       "      <td>REA</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>MLB-NEBULIZERS</td>\n",
       "      <td>344151</td>\n",
       "      <td>Inalador E Nebulizador Infantil Nebdog Superfl...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>MLB9838512</td>\n",
       "      <td>MLB9838510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>464801</td>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>156.78</td>\n",
       "      <td>REA</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>MLB-NEBULIZERS</td>\n",
       "      <td>344151</td>\n",
       "      <td>Inalador E Nebulizador Infantil Nebdog Superfl...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>MLB9838512</td>\n",
       "      <td>MLB9838510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>464801</td>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>0</td>\n",
       "      <td>156.78</td>\n",
       "      <td>REA</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>MLB-NEBULIZERS</td>\n",
       "      <td>344151</td>\n",
       "      <td>Inalador E Nebulizador Infantil Nebdog Superfl...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>MLB9838512</td>\n",
       "      <td>MLB9838510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>464801</td>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>0</td>\n",
       "      <td>156.78</td>\n",
       "      <td>REA</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>MLB-NEBULIZERS</td>\n",
       "      <td>344151</td>\n",
       "      <td>Inalador E Nebulizador Infantil Nebdog Superfl...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>MLB9838512</td>\n",
       "      <td>MLB9838510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>464801</td>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>156.78</td>\n",
       "      <td>REA</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>MLB-NEBULIZERS</td>\n",
       "      <td>344151</td>\n",
       "      <td>Inalador E Nebulizador Infantil Nebdog Superfl...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>MLB9838512</td>\n",
       "      <td>MLB9838510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sku        date  sold_quantity  current_price currency listing_type  \\\n",
       "0  464801  2021-02-01              0         156.78      REA      classic   \n",
       "1  464801  2021-02-02              0         156.78      REA      classic   \n",
       "2  464801  2021-02-03              0         156.78      REA      classic   \n",
       "3  464801  2021-02-04              0         156.78      REA      classic   \n",
       "4  464801  2021-02-05              1         156.78      REA      classic   \n",
       "\n",
       "  shipping_logistic_type shipping_payment  minutes_active  item_domain_id  \\\n",
       "0            fulfillment    free_shipping          1440.0  MLB-NEBULIZERS   \n",
       "1            fulfillment    free_shipping          1440.0  MLB-NEBULIZERS   \n",
       "2            fulfillment    free_shipping          1440.0  MLB-NEBULIZERS   \n",
       "3            fulfillment    free_shipping          1440.0  MLB-NEBULIZERS   \n",
       "4            fulfillment    free_shipping          1440.0  MLB-NEBULIZERS   \n",
       "\n",
       "   item_id                                         item_title site_id  \\\n",
       "0   344151  Inalador E Nebulizador Infantil Nebdog Superfl...     MLB   \n",
       "1   344151  Inalador E Nebulizador Infantil Nebdog Superfl...     MLB   \n",
       "2   344151  Inalador E Nebulizador Infantil Nebdog Superfl...     MLB   \n",
       "3   344151  Inalador E Nebulizador Infantil Nebdog Superfl...     MLB   \n",
       "4   344151  Inalador E Nebulizador Infantil Nebdog Superfl...     MLB   \n",
       "\n",
       "   product_id product_family_id  \n",
       "0  MLB9838512        MLB9838510  \n",
       "1  MLB9838512        MLB9838510  \n",
       "2  MLB9838512        MLB9838510  \n",
       "3  MLB9838512        MLB9838510  \n",
       "4  MLB9838512        MLB9838510  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the product details into the main train dataframe\n",
    "train = train.merge(df_details, on='sku')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37660279, 15)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check train shape\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku                         int64\n",
       "date                       object\n",
       "sold_quantity               int64\n",
       "current_price             float64\n",
       "currency                   object\n",
       "listing_type               object\n",
       "shipping_logistic_type     object\n",
       "shipping_payment           object\n",
       "minutes_active            float64\n",
       "item_domain_id             object\n",
       "item_id                     int64\n",
       "item_title                 object\n",
       "site_id                    object\n",
       "product_id                 object\n",
       "product_family_id          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fix the date\n",
    "train['date'] = pd.to_datetime(train['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku                              0\n",
       "date                             0\n",
       "sold_quantity                    0\n",
       "current_price                    0\n",
       "currency                         0\n",
       "listing_type                     0\n",
       "shipping_logistic_type           0\n",
       "shipping_payment                 0\n",
       "minutes_active                   0\n",
       "item_domain_id                 177\n",
       "item_id                          0\n",
       "item_title                       0\n",
       "site_id                          0\n",
       "product_id                36093373\n",
       "product_family_id         33052904\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing data\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering\n",
    "\n",
    "I created new features to play with XGBRegressor:\n",
    "* The presence of product family (not that good since there are a lot of missing data)\n",
    "* I wish I had more time to try embeddings with the description (thank you boss!!), so I created a dumb feature regarding the word count\n",
    "* Two features regarding availability of the product: if it was all day available (available_24h) and if it showed up a least 1 minute in the last 24h (available)\n",
    "* Two date features: weekday and is_weekend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['product_family_present'] = (train['product_family_id'].notnull()).map({True: 1, False: 0})\n",
    "train['desc_word_count'] = train['item_title'].str.lower().str.split().apply(lambda l: len(l))\n",
    "\n",
    "train['available_24h'] = (train['minutes_active'] == 1440).map({True: 1, False: 0})\n",
    "train['available'] = (train['minutes_active'] > 0).map({True: 1, False: 0})\n",
    "\n",
    "train['weekday'] = train['date'].dt.weekday\n",
    "train['is_weekend'] = (train['weekday'] >= 5).map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>date</th>\n",
       "      <th>sold_quantity</th>\n",
       "      <th>current_price</th>\n",
       "      <th>currency</th>\n",
       "      <th>listing_type</th>\n",
       "      <th>shipping_logistic_type</th>\n",
       "      <th>shipping_payment</th>\n",
       "      <th>minutes_active</th>\n",
       "      <th>item_domain_id</th>\n",
       "      <th>...</th>\n",
       "      <th>item_title</th>\n",
       "      <th>site_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_family_id</th>\n",
       "      <th>product_family_present</th>\n",
       "      <th>desc_word_count</th>\n",
       "      <th>available_24h</th>\n",
       "      <th>available</th>\n",
       "      <th>weekday</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>464801</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>156.78</td>\n",
       "      <td>REA</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>MLB-NEBULIZERS</td>\n",
       "      <td>...</td>\n",
       "      <td>Inalador E Nebulizador Infantil Nebdog Superfl...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>MLB9838512</td>\n",
       "      <td>MLB9838510</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>464801</td>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>156.78</td>\n",
       "      <td>REA</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>MLB-NEBULIZERS</td>\n",
       "      <td>...</td>\n",
       "      <td>Inalador E Nebulizador Infantil Nebdog Superfl...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>MLB9838512</td>\n",
       "      <td>MLB9838510</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>464801</td>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>0</td>\n",
       "      <td>156.78</td>\n",
       "      <td>REA</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>MLB-NEBULIZERS</td>\n",
       "      <td>...</td>\n",
       "      <td>Inalador E Nebulizador Infantil Nebdog Superfl...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>MLB9838512</td>\n",
       "      <td>MLB9838510</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>464801</td>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>0</td>\n",
       "      <td>156.78</td>\n",
       "      <td>REA</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>MLB-NEBULIZERS</td>\n",
       "      <td>...</td>\n",
       "      <td>Inalador E Nebulizador Infantil Nebdog Superfl...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>MLB9838512</td>\n",
       "      <td>MLB9838510</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>464801</td>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>156.78</td>\n",
       "      <td>REA</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>MLB-NEBULIZERS</td>\n",
       "      <td>...</td>\n",
       "      <td>Inalador E Nebulizador Infantil Nebdog Superfl...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>MLB9838512</td>\n",
       "      <td>MLB9838510</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sku       date  sold_quantity  current_price currency listing_type  \\\n",
       "0  464801 2021-02-01              0         156.78      REA      classic   \n",
       "1  464801 2021-02-02              0         156.78      REA      classic   \n",
       "2  464801 2021-02-03              0         156.78      REA      classic   \n",
       "3  464801 2021-02-04              0         156.78      REA      classic   \n",
       "4  464801 2021-02-05              1         156.78      REA      classic   \n",
       "\n",
       "  shipping_logistic_type shipping_payment  minutes_active  item_domain_id  \\\n",
       "0            fulfillment    free_shipping          1440.0  MLB-NEBULIZERS   \n",
       "1            fulfillment    free_shipping          1440.0  MLB-NEBULIZERS   \n",
       "2            fulfillment    free_shipping          1440.0  MLB-NEBULIZERS   \n",
       "3            fulfillment    free_shipping          1440.0  MLB-NEBULIZERS   \n",
       "4            fulfillment    free_shipping          1440.0  MLB-NEBULIZERS   \n",
       "\n",
       "   ...                                         item_title site_id  product_id  \\\n",
       "0  ...  Inalador E Nebulizador Infantil Nebdog Superfl...     MLB  MLB9838512   \n",
       "1  ...  Inalador E Nebulizador Infantil Nebdog Superfl...     MLB  MLB9838512   \n",
       "2  ...  Inalador E Nebulizador Infantil Nebdog Superfl...     MLB  MLB9838512   \n",
       "3  ...  Inalador E Nebulizador Infantil Nebdog Superfl...     MLB  MLB9838512   \n",
       "4  ...  Inalador E Nebulizador Infantil Nebdog Superfl...     MLB  MLB9838512   \n",
       "\n",
       "  product_family_id product_family_present  desc_word_count  available_24h  \\\n",
       "0        MLB9838510                      1                8              1   \n",
       "1        MLB9838510                      1                8              1   \n",
       "2        MLB9838510                      1                8              1   \n",
       "3        MLB9838510                      1                8              1   \n",
       "4        MLB9838510                      1                8              1   \n",
       "\n",
       "   available  weekday  is_weekend  \n",
       "0          1        0           0  \n",
       "1          1        1           0  \n",
       "2          1        2           0  \n",
       "3          1        3           0  \n",
       "4          1        4           0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look how it went\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['item_title', 'product_family_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For evaluation, I chose to train in feb and validate march and vice-versa. Let's create the folds\n",
    "train['fold'] = train['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./data/test_data.csv\", index_col=0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['item_domain_id', 'currency',\n",
    "        'listing_type', 'shipping_logistic_type',\n",
    "        'shipping_payment', 'site_id',\n",
    "        'available_24h', 'available', 'weekday', 'is_weekend']\n",
    "\n",
    "from category_encoders import OrdinalEncoder\n",
    "\n",
    "enc = OrdinalEncoder(cats)\n",
    "train = enc.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tr_ts():\n",
    "    for fold in [2, 3]:\n",
    "        ts = train[train['fold'] != fold]['date'].max()\n",
    "        ts = train[(train['fold'] != fold) & (train['date'] == ts)].index\n",
    "        yield train.index[train['fold'] == fold], ts, fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[0.09871192514273254, 9, 0.16531200313642108, 0.9491364637917304, 1.2337280871824563, 120]\n",
      "9.122782707760251\n",
      "8.677063115556907\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 116.7530\n",
      "Function value obtained: 8.8999\n",
      "Current minimum: 8.8999\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[0.0059678992438367785, 7, 0.8919851637254288, 0.8116798250174155, 1.3101407817629525, 158]\n",
      "6.778292665833115\n",
      "6.988827156850929\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 123.0874\n",
      "Function value obtained: 6.8836\n",
      "Current minimum: 6.8836\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[0.007707362534461022, 3, 0.5309725180523154, 0.8725658221213098, 1.4526327599071185, 130]\n",
      "6.778292665833115\n",
      "6.988827156850929\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 116.1495\n",
      "Function value obtained: 6.8836\n",
      "Current minimum: 6.8836\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[0.07555367242122375, 8, 0.6943734643715279, 0.7724817535436286, 1.0918728005543306, 156]\n",
      "9.204470596778947\n",
      "8.751471211232214\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 137.1558\n",
      "Function value obtained: 8.9780\n",
      "Current minimum: 6.8836\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[0.0537081884337239, 8, 0.7966430234547655, 0.29574497679507267, 1.0586507692885478, 201]\n",
      "9.267445856360247\n",
      "8.813289289510646\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 137.7537\n",
      "Function value obtained: 9.0404\n",
      "Current minimum: 6.8836\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[0.01535080081765723, 7, 0.4206090910721478, 0.22779580818630313, 1.2867333441403543, 43]\n",
      "6.050640938257535\n",
      "6.431758099253907\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 109.7649\n",
      "Function value obtained: 6.2412\n",
      "Current minimum: 6.2412\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[0.036866248434672594, 5, 0.08075418006725515, 0.6116269878296181, 1.654029372935623, 90]\n",
      "6.01003924229241\n",
      "6.436961823325516\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 91.6081\n",
      "Function value obtained: 6.2235\n",
      "Current minimum: 6.2235\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[0.007803133051910397, 3, 0.11602775456833962, 0.47231467379432884, 1.095210537841007, 271]\n",
      "6.186791231496342\n",
      "6.645209985648864\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 104.3003\n",
      "Function value obtained: 6.4160\n",
      "Current minimum: 6.2235\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[0.001733727891374242, 6, 0.1252607040923236, 0.8751752010767558, 1.9013438979751707, 90]\n",
      "6.778292665833115\n",
      "6.988827156850929\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 106.2120\n",
      "Function value obtained: 6.8836\n",
      "Current minimum: 6.2235\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[0.014749532034944692, 6, 0.6025444860164502, 0.9108820910034702, 1.2583691898194014, 70]\n",
      "6.00579832965574\n",
      "6.400405972012914\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 108.8891\n",
      "Function value obtained: 6.2031\n",
      "Current minimum: 6.2031\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "[0.02474007129092552, 4, 0.95, 0.95, 1.99, 20]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-7e9d6d26c77a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m          \u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.99\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m          (1, 300)]\n\u001b[1;32m---> 62\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtune\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mf:\\leon\\venvs\\ml\\lib\\site-packages\\skopt\\optimizer\\gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         callback=callback, n_jobs=n_jobs, model_queue_size=model_queue_size)\n\u001b[0m",
      "\u001b[1;32mf:\\leon\\venvs\\ml\\lib\\site-packages\\skopt\\optimizer\\base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[0mnext_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-7e9d6d26c77a>\u001b[0m in \u001b[0;36mtune\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mppp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stock'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mppp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sku'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mppp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mppp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stock'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mppp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'days_to_so'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mppp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stock'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mppp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mdays_to_so_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mppp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sku'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'days_to_so'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sku\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays_to_so_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\leon\\venvs\\ml\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5544\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5545\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5546\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5547\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\leon\\venvs\\ml\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     ) -> \"BlockManager\":\n\u001b[1;32m--> 595\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m     def convert(\n",
      "\u001b[1;32mf:\\leon\\venvs\\ml\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\leon\\venvs\\ml\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    593\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\leon\\venvs\\ml\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot convert non-finite values (NA or inf) to integer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "def tune(params):\n",
    "    print(params)\n",
    "    features = [\"current_price\", \"minutes_active\", 'product_family_present', 'desc_word_count'] + cats\n",
    "\n",
    "    mean_rps = 0.\n",
    "    for tr, ts, fold in gen_tr_ts():\n",
    "        X = train[features]\n",
    "        y = train['sold_quantity']\n",
    "\n",
    "        Xtr = X.iloc[tr]\n",
    "        ytr = y.iloc[tr]\n",
    "        Xval = X.iloc[ts]\n",
    "        yval = y.iloc[ts]\n",
    "\n",
    "        mdl = XGBRegressor(n_estimators=100, learning_rate=params[0],\n",
    "                           max_depth=params[1],\n",
    "                           subsample=params[2],\n",
    "                           colsample_bytree=params[3],\n",
    "                           tweedie_variance_power=params[4],\n",
    "                           min_child_weight=params[5],\n",
    "                           random_state=0, objective=\"reg:tweedie\",\n",
    "                           base_score=1e-3,\n",
    "                           tree_method='gpu_hist')\n",
    "        mdl.fit(Xtr, ytr)\n",
    "        p = mdl.predict(Xval)\n",
    "\n",
    "        ## EVAL\n",
    "        pp = train[train['fold'] != fold][['sku', 'date', 'sold_quantity']]\n",
    "        pp['stock'] = pp['sku'].map(test)\n",
    "        pp = pp.sort_values([\"sku\", \"date\"])\n",
    "        pp['cumulative_y'] = pp.groupby(\"sku\")['sold_quantity'].cumsum()\n",
    "\n",
    "        pp = pp.dropna(subset=['stock'])\n",
    "        pp['stockout_y'] = pp['cumulative_y'] >= pp['stock']\n",
    "\n",
    "        first_so_y = pp[pp['stockout_y']].groupby(\"sku\").first()\n",
    "        days_to_so_y = (first_so_y[\"date\"] - pp[\"date\"].min()) / np.timedelta64(1, 'D')\n",
    "        days_to_so_y = days_to_so_y.reindex(pp['sku'].unique()).fillna(30.).clip(1, 30)\n",
    "\n",
    "        ppp = train.iloc[ts][['sku']]\n",
    "        # p[~np.isfinite(p)] = 17.\n",
    "        ppp['p'] = p\n",
    "        ppp['stock'] = ppp['sku'].map(test)\n",
    "        ppp = ppp.dropna(subset=['stock'])\n",
    "        ppp['days_to_so'] = (ppp['stock'] / ppp['p']).astype(int).fillna(30.).clip(1, 30)\n",
    "        days_to_so_p = ppp[['sku', 'days_to_so']].set_index(\"sku\").squeeze().reindex(days_to_so_y.index)\n",
    "\n",
    "        days_to_so_p2 = utils.pred_list_to_tweedie(days_to_so_p, phi=2, p=1.5)\n",
    "\n",
    "        rps = utils.rps(days_to_so_y, days_to_so_p2, probs=True)\n",
    "        mean_rps += rps\n",
    "        print(rps)\n",
    "    return mean_rps / 2\n",
    "\n",
    "\n",
    "space = [(1e-3, 1e-1, 'log-uniform'),\n",
    "         (1, 10),\n",
    "         (0.05, 0.95),\n",
    "         (0.05, 0.95),\n",
    "         (1.0, 1.99),\n",
    "         (1, 300)]\n",
    "res = gp_minimize(tune, space, random_state=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.001, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.9108820910034702, gamma=0,\n",
       "             gpu_id=0, importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.014749532034944692, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=70, missing=nan,\n",
       "             monotone_constraints='(0,0,0,0,0,0,0,0,0,0,0,0,0,0)',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:tweedie', random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "             scale_pos_weight=None, subsample=0.6025444860164502,\n",
       "             tree_method='gpu_hist', tweedie_variance_power=1.2583691898194014,\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\"current_price\", \"minutes_active\", 'product_family_present', 'desc_word_count'] + cats\n",
    "\n",
    "# Some tests with parameters\n",
    "# params = [0.036887776337184194, 3, 0.2612410543047176, 0.72389895876477, 1.696027970970498, 93]\n",
    "#params = [0.036866248434672594, 5, 0.08075418006725515, 0.6116269878296181, 1.654029372935623, 90]\n",
    "params = [0.014749532034944692, 6, 0.6025444860164502, 0.9108820910034702, 1.2583691898194014, 70]\n",
    "\n",
    "mdl = XGBRegressor(n_estimators=100, learning_rate=params[0],\n",
    "                   max_depth=params[1],\n",
    "                   subsample=params[2],\n",
    "                   colsample_bytree=params[3],\n",
    "                   tweedie_variance_power=params[4],\n",
    "                   min_child_weight=params[5],\n",
    "                   random_state=0, objective=\"reg:tweedie\",\n",
    "                   base_score=1e-3,\n",
    "                   tree_method='gpu_hist')\n",
    "\n",
    "mdl.fit(train[features], train['sold_quantity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sales on the last day\n",
    "test_df = train[train['date'] == \"2021-03-31\"]\n",
    "test_df = test_df[test_df['sku'].isin(test.index)]\n",
    "\n",
    "p = mdl.predict(test_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the prediction for one day, we must calculate how many days the sock will end in 30 days (even the same variable names, thanks a lot Mario Filho <3)\n",
    "spp = test_df[['sku']].copy()\n",
    "spp['p'] = p\n",
    "spp['stock'] = spp['sku'].map(test)\n",
    "spp['days_to_so'] = (spp['stock'] / spp['p']).fillna(30.).clip(1, 30).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A little \"smart dumbness\". If the model is too far from the mean sales, let's bring the predictions back\n",
    "# This should be our baseline, but it showed a good ensemble with the XGBRegressor\n",
    "df_dumb_prediction_by_sku = train.groupby('sku')['sold_quantity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many days the stock would end with the mean sales\n",
    "spp['mean_p'] = spp['sku'].map(df_dumb_prediction_by_sku)\n",
    "spp['mean_days_to_so'] = (spp['stock'] / spp['mean_p']).fillna(30.).clip(1, 30).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple mean ensemble\n",
    "spp['final_days_to_so'] = ((spp['days_to_so'] + spp['mean_days_to_so']) / 2).fillna(30.).clip(1, 30).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the predictions of best submission without post processing\n",
    "spp[['final_days_to_so']].to_parquet('./models/predictions_best_submission_11.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, for the first post processing, we compare the predictions with plain logic (sometimes machine are just dumb)\n",
    "# If the stock is too big based on the items sold in the previous months, it wont sell until the last day (it'll take 30 days)\n",
    "df_sales_by_sku = train.groupby('sku').sum('sold_quantity')\n",
    "\n",
    "df_sales_by_sku.drop(['current_price', 'minutes_active'], axis=1, inplace=True)\n",
    "\n",
    "df_sales_by_sku = df_sales_by_sku.merge(test, on='sku')\n",
    "\n",
    "df_sales_by_sku['mean_sales_by_day'] = df_sales_by_sku['sold_quantity'] / 60\n",
    "df_sales_by_sku['mean_sales_by_month'] = df_sales_by_sku['sold_quantity'] / 2\n",
    "df_sales_by_sku['diff_sold_stock'] = df_sales_by_sku['sold_quantity'] - df_sales_by_sku['target_stock']\n",
    "\n",
    "df_predictions = pd.read_parquet('./models/predictions_final_day_xgb.parquet')\n",
    "df_predictions.reset_index(level=0, inplace=True)\n",
    "\n",
    "df_predictions.columns = ['sku', 'predictions']\n",
    "\n",
    "# Now we can set the inventory days to 30 to all skus with stock bigger than sales in the previous months\n",
    "skus_in_predictions_with_30 = set(df_predictions.loc[df_predictions['predictions'] == 30, 'sku'].values)\n",
    "skus_with_inventory_bigger_than_sales = set(df_sales_by_sku.loc[df_sales_by_sku['diff_sold_stock'] <= 0, :].index)\n",
    "\n",
    "df_predictions.loc[df_predictions['sku'].isin(skus_with_inventory_bigger_than_sales), 'predictions'] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a intermediate prediction (i've tested it to see if the post processing were effective and they were)\n",
    "prob_array = utils.pred_list_to_tweedie(df_predictions['predictions'].values, phi=2., p=1.5)\n",
    "pd.set_option(\"display.max_columns\", 31)\n",
    "pd.DataFrame(prob_array).round(4).to_csv(\"./submissions/2021_08_22_really_naive.csv.gz\", header=False, index=False,\n",
    "                                         compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the last post processing, based on Mario Filho's approach once again: predict if the sku is available\n",
    "# and start the distribution only when the product is active (by the prediction)\n",
    "# The main idea is to use a regressor to predict the day the product will start being active (visible),\n",
    "# a product that is not active will not sell until the day it is active\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "test = pd.read_csv(\"./data/test_data.csv\").set_index(\"sku\").squeeze()\n",
    "train = pd.read_parquet(\"./data/0.parquet\")\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "cats = ['item_domain_id', 'currency', 'listing_type', 'shipping_logistic_type', 'shipping_payment', 'site_id']\n",
    "for cat in cats:\n",
    "    train[cat] = train[cat].astype(\"category\").cat.codes\n",
    "\n",
    "train.loc[train[\"minutes_active\"] == 0, \"active\"] = 0\n",
    "train[\"active\"] = train[\"active\"].fillna(1)\n",
    "\n",
    "act = train[train['active'] == 1][['sku', 'date']].sort_values(\"date\")\n",
    "act['active_date'] = act['date']\n",
    "inact = train[train['active'] == 0][['sku', 'date', 'shipping_logistic_type', 'shipping_payment',\n",
    "                                     'listing_type', 'currency', 'current_price', 'item_domain_id',\n",
    "                                     'site_id']].sort_values(\"date\")\n",
    "all_ = pd.merge_asof(inact, act, on=['date'], direction='forward', by=['sku']).dropna(subset=['active_date'])\n",
    "all_['days_to_active'] = (all_['active_date'] - all_['date']) / np.timedelta64(1, 'D')\n",
    "all_['days_since_inactive'] = (all_['date'] - all_.groupby(\"sku\")[\"date\"].transform(\"min\")) / np.timedelta64(1, 'D')\n",
    "y = all_['days_to_active'].copy()\n",
    "all_.corr(method='spearman')\n",
    "\n",
    "Xtr = all_.loc[all_['date'] < \"2021-03-01\", ['days_since_inactive', 'current_price'] + cats]\n",
    "Xval = all_.loc[all_['date'] >= \"2021-03-01\", ['days_since_inactive', 'current_price'] + cats]\n",
    "\n",
    "ytr = y[all_['date'] < \"2021-03-01\"]\n",
    "yval = y[all_['date'] >= \"2021-03-01\"]\n",
    "\n",
    "mdl = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=0, n_jobs=6, tree_method='hist')\n",
    "mdl.fit(Xtr, ytr)\n",
    "p = mdl.predict(Xval)\n",
    "np.sqrt(mean_squared_error(yval, p))\n",
    "\n",
    "all_t = train[train['active'] == 0].copy()\n",
    "\n",
    "all_t['days_since_inactive'] = (all_t['date'] - all_t.groupby(\"sku\")[\"date\"].transform(\"min\")) / np.timedelta64(1, 'D')\n",
    "all_t = all_t.groupby(\"sku\").last()\n",
    "all_t = all_t[all_t['date'] == \"2021-03-31\"].copy()\n",
    "\n",
    "X = all_.loc[:, ['days_since_inactive', 'current_price'] + cats]\n",
    "Xt = all_t.loc[:, ['days_since_inactive', 'current_price'] + cats]\n",
    "\n",
    "mdl = xgb.XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=0, n_jobs=6, tree_method='hist')\n",
    "mdl.fit(X, y)\n",
    "p = mdl.predict(Xt)\n",
    "\n",
    "p2 = pd.Series(p.round(), index=Xt.index).reindex(test.index).dropna().astype(int)\n",
    "\n",
    "# reading the post processed submission\n",
    "sub = pd.read_csv(\"./submissions/2021_08_22_really_naive.csv.gz\", header=None)  # 4.23\n",
    "sub_ = sub.copy()\n",
    "sub_.index = test.index\n",
    "\n",
    "for sku in p2.index:\n",
    "    s = sub_.loc[sku].copy()\n",
    "    days = p2.loc[sku]\n",
    "    s.iloc[:days] = s.iloc[:days] * 0.5\n",
    "    s = s / s.sum()\n",
    "    sub_.loc[sku, :] = s\n",
    "\n",
    "# Best score LB 4.20\n",
    "sub_.round(4).to_csv(\"./submissions/2021_08_22_really_naive_v2.csv.gz\", header=False, index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
